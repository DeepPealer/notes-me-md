tags: [data-engineering, bigdata, distributed-systems, mapreduce, mpp, hadoop, spark, interviewprep]  
alias: [MapReduce, MPP, Массово-параллельная обработка]  
related: [[ETL / ELT Concepts]], [[Data Warehousing]], [[NoSQL Concepts and CAP Theorem]]

MapReduce и MPP — это две парадигмы **распределенных вычислений**. Их общая цель — обрабатывать огромные наборы данных, которые не помещаются на один сервер, путем **распараллеливания** работы на множество машин (узлов) в кластере.

> **Основная идея**: "Разделяй и властвуй". Большая задача разбивается на множество мелких подзадач, которые выполняются одновременно на разных узлах, а затем их результаты собираются вместе.

---

## [[MapReduce]]

MapReduce — это **программная модель** (и связанная с ней реализация) для обработки больших наборов данных, популяризированная Google. Она стала сердцем экосистемы **Apache Hadoop**.

Модель состоит из двух основных шагов, которые определяет пользователь:

1. **Map (Отображение)**
    
    - **Что делает?** Принимает входные данные и "отображает" их в промежуточные пары (ключ, значение). Этап Map выполняется параллельно на всех узлах кластера над своими частями данных.
        
    - **Аналогия**: Вы даете стопку анкет нескольким людям (Map-задачи). Каждый человек проходит по своим анкетам и на отдельном листочке выписывает: (Город, 1), (Город, 1) для каждого жителя.
        
2. **Reduce (Свёртка)**
    
    - **Что делает?** Принимает промежуточные пары, сгруппированные по ключу, и "сворачивает" (агрегирует) их в итоговый результат.
        
    - **Аналогия**: Вы собираете все листочки, сортируете их по городам. Затем отдельный человек (Reduce-задача) для каждого города берет все единички и суммирует их, получая итоговое число жителей.
        

**Промежуточный этап Shuffle and Sort**: Между Map и Reduce фреймворк автоматически выполняет очень важный этап — перемешивание и сортировку. Он собирает все пары (ключ, значение) с разных узлов и группирует их так, чтобы все значения с одинаковым ключом попали на одну и ту же Reduce-задачу.

**Классический пример — подсчет слов (Word Count):**

- **Input**: "hello world bye world"
    
- **Map Phase**:
    
    - map("hello world bye world") -> (hello, 1), (world, 1), (bye, 1), (world, 1)
        
- **Shuffle & Sort Phase**:
    
    - Группирует по ключу -> (bye, [1]), (hello, [1]), (world, [1, 1])
        
- **Reduce Phase**:
    
    - reduce("bye", [1]) -> (bye, 1)
        
    - reduce("hello", [1]) -> (hello, 1)
        
    - reduce("world", [1, 1]) -> (world, 2)
        

**Характеристики MapReduce:**

- **Отказоустойчивость**: Разработан для работы на **дешевом, ненадежном оборудовании**. Если узел падает, фреймворк автоматически перезапускает его задачу на другом узле.
    
- **Пакетная обработка (Batch Processing)**: Идеально подходит для очень больших, длительных задач, которые не требуют ответа в реальном времени.
    
- **Гибкость**: Может обрабатывать неструктурированные и полуструктурированные данные.
    
- **Медлительность**: Из-за интенсивного чтения/записи на диск между этапами (для обеспечения отказоустойчивости), MapReduce является относительно медленным. **Apache Spark**, который выполняет операции в памяти, пришел ему на смену как более быстрая альтернатива.
    

---

## [[MPP (Massively Parallel Processing)]] — Массово-параллельная обработка

MPP — это **архитектура баз данных**, в которой множество серверов (узлов) работают параллельно как единая система.

**Идея**: Данные в таблице физически **распределяются (sharded/partitioned)** между всеми узлами кластера. Когда приходит SQL-запрос, **координатор (leader node)** распараллеливает его выполнение, и каждый узел обрабатывает только ту часть данных, которая хранится на нем.

> **Основное отличие от MapReduce**: MPP-системы — это **базы данных**. У них есть понятия таблиц, схем, [[SQL]], транзакций. MapReduce — это более низкоуровневая модель для произвольной обработки данных.

**Характеристики MPP:**

- **Архитектура "Shared Nothing"**: У каждого узла есть свой собственный процессор, память и диск. Они не делят ресурсы, что позволяет масштабироваться линейно.
    
- **Высокая скорость**: Так как данные и вычисления находятся рядом, а обмен данными происходит по высокоскоростной сети, MPP-базы очень быстры для аналитических запросов.
    
- **Предназначены для структурированных данных**: Лучше всего работают с данными, организованными в таблицы.
    
- **Обычно используются для [[OLAP vs OLTP|OLAP]]**: Это архитектура большинства современных облачных хранилищ данных.
    
- **Оборудование**: Исторически требовали дорогого, специализированного оборудования, но облачные версии (как BigQuery) демократизировали этот подход.
    

**Примеры MPP-баз данных**:

- **Облачные**: Google BigQuery, Amazon Redshift, Snowflake.
    
- **Локальные**: Teradata, Vertica, Greenplum.
    

---

### Сводное сравнение

|   |   |   |
|---|---|---|
|Характеристика|MapReduce (Hadoop)|MPP (Базы данных)|
|**Что это?**|Программная модель для пакетной обработки|Архитектура распределенных баз данных|
|**Основной интерфейс**|Программный код (Java, Python)|SQL|
|**Данные**|В основном неструктурированные (файлы в HDFS)|Структурированные (таблицы)|
|**Отказоустойчивость**|Очень высокая, для дешевого оборудования|Высокая, но обычно для более надежного оборудования|
|**Скорость**|Медленная (дисковые операции)|Очень высокая (оптимизировано для скорости)|
|**Основной сценарий**|ETL, сложная обработка неструктурированных данных|Интерактивная аналитика, хранилища данных (BI)|

---

### Популярные вопросы на собеседовании

- **"Объясните концепцию MapReduce на примере подсчета слов."**
    
- **"В чем ключевое различие между архитектурой MapReduce и MPP?"**
    
    - Ответ: MapReduce — это модель обработки файлов, а MPP — это архитектура баз данных. MPP-системы предоставляют SQL-интерфейс и оптимизированы для быстрой аналитики структурированных данных, в то время как MapReduce — более универсальная, но медленная модель для пакетной обработки любых данных.
        
- **"Почему Apache Spark во многом заменил MapReduce?"**
    
    - Ответ: Spark выполняет аналогичные вычисления, но делает это преимущественно **в оперативной памяти**, а не на диске, что делает его на порядки быстрее. Также Spark предоставляет более удобные и высокоуровневые API.
        
- **"Приведите примеры MPP-систем."**