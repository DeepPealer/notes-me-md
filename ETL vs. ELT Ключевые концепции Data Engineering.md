tags: [data-engineering, etl, elt, dbt, bigdata, data-warehouse, data-lake, interviewprep]  
alias: [ETL, ELT, Extract Transform Load, Extract Load Transform]  
related: [[Data Warehousing]], [[Data Lakes]], [[SQL]], [[Cloud Data Platforms]], [[dbt]]

**ETL (Extract, Transform, Load)** и **ELT (Extract, Load, Transform)** — это два подхода к процессу перемещения данных из различных источников в единую систему хранения (чаще всего, [[Data Warehousing|хранилище данных]]) для анализа и отчетности.

Разница между ними заключается всего в одном — в **порядке** выполнения операций, но это кардинально меняет архитектуру, инструменты и философию всего процесса.

---

## [[ETL]] (Extract, Transform, Load) — "Классический" подход

ETL был доминирующим подходом на протяжении десятилетий, в эпоху "on-premise" (локальных) хранилищ данных.

**Порядок действий:**

1. **Extract (Извлечение)**: Данные извлекаются из исходных систем (базы данных, CRM, ERP, файлы).
    
2. **Transform (Трансформация)**: Извлеченные данные поступают на **промежуточный (staging) сервер**, где специальный ETL-инструмент выполняет все тяжелые трансформации:
    
    - Очистка данных (исправление ошибок, удаление дубликатов).
        
    - Обогащение (объединение с данными из других источников).
        
    - Агрегация (расчет итогов, средних значений).
        
    - Приведение к единой, строго определенной схеме (бизнес-модели).
        
3. **Load (Загрузка)**: Уже **трансформированные, чистые и структурированные** данные загружаются в целевое хранилище данных (Data Warehouse).
    

> **Ключевая идея ETL**: Вся "грязная работа" и сложные вычисления происходят **до** загрузки данных в хранилище. Хранилище получает уже готовые к анализу витрины данных.

**Характеристики:**

- **Требует мощного ETL-сервера**: Трансформации — ресурсоемкий процесс.
    
- **Строгая схема при записи (Schema-on-Write)**: Данные должны соответствовать заранее определенной структуре хранилища.
    
- **Более медленная загрузка**: Данные становятся доступны для анализа только после завершения длительного этапа трансформации.
    

---

## [[ELT]] (Extract, Load, Transform) — "Современный" облачный подход

ELT стал стандартом де-факто в эпоху облачных вычислений.

**Порядок действий:**

1. **Extract (Извлечение)**: Данные извлекаются из источников (так же, как в ETL).
    
2. **Load (Загрузка)**: **Сырые, необработанные** данные немедленно загружаются в целевую систему. Этой системой обычно является облачное хранилище данных (Snowflake, BigQuery, Redshift) или [[Data Lakes|озеро данных]].
    
3. **Transform (Трансформация)**: Все трансформации происходят **непосредственно внутри хранилища данных** уже после загрузки. Для этого используются мощные вычислительные ресурсы самого хранилища и, как правило, SQL-запросы.
    

> **Ключевая идея ELT**: "Сначала загрузи всё как есть, а разбираться будем потом". Мощности облачных хранилищ позволяют выполнять трансформации "на лету" прямо там, где хранятся данные.

**Характеристики:**

- **Использует мощность хранилища**: Не нужен отдельный ETL-сервер.
    
- **Гибкая схема при чтении (Schema-on-Read)**: Сначала загружаем данные, а потом решаем, как их структурировать.
    
- **Быстрая загрузка**: Сырые данные становятся доступны почти мгновенно.
    
- **Сохранение сырых данных**: Так как мы загружаем данные "как есть", у нас всегда есть возможность вернуться к исходнику.
    

---

### Почему ELT стал доминировать? (Важно для собеседования)

Две основные причины:

1. **Дешевое облачное хранение**: Появление "озер данных" (Data Lakes) на базе Amazon S3, Google Cloud Storage и т.д. сделало хранение огромных объемов сырых данных очень дешевым.
    
2. **Мощные облачные хранилища (Cloud Data Warehouses)**: Такие системы, как Snowflake, Google BigQuery и Amazon Redshift, разделили хранение и вычисления, предоставив практически бесконечную вычислительную мощность по запросу. Они способны эффективно выполнять сложнейшие SQL-трансформации над петабайтами данных.
    

### Роль dbt (data build tool)

dbt — это идеальный инструмент для **"T" в ELT**. Он не извлекает и не загружает данные. Он позволяет инженерам и аналитикам эффективно управлять всем циклом трансформаций **внутри хранилища данных** с помощью простого SQL, добавляя к нему версионирование (через [[Git]]), тестирование и документирование.

---

### Сводное сравнение

|   |   |   |
|---|---|---|
|Характеристика|ETL (Extract, Transform, Load)|ELT (Extract, Load, Transform)|
|**Порядок**|Извлечение -> Трансформация -> Загрузка|Извлечение -> Загрузка -> Трансформация|
|**Место трансформации**|Промежуточный ETL-сервер|Внутри целевого хранилища данных|
|**Доступность данных**|Медленнее (после трансформации)|Быстрее (сразу после загрузки)|
|**Гибкость**|Низкая (требует предопределенной схемы)|Высокая (схема определяется на этапе анализа)|
|**Хранение сырых данных**|Обычно нет|Да, всегда есть доступ к исходникам|
|**Типичные инструменты**|Informatica, Talend, SSIS|Fivetran, Stitch (для EL), **dbt (для T)**|

---

### Популярные вопросы на собеседовании

- **"В чем основное различие между ETL и ELT?"**
    
- **"Почему в последние годы ELT стал более популярным подходом?"**
    
    - Ответ: Из-за развития облачных технологий: дешевого хранения данных и мощных облачных хранилищ, которые могут сами выполнять трансформации.
        
- **"Представьте, что вы строите аналитическую платформу для стартапа. Какой подход вы выберете, ETL или ELT, и почему?"**
    
    - Ответ: Я бы выбрал ELT. Это позволит нам быстро начать собирать все сырые данные, не тратя много времени на разработку сложных ETL-процессов. Это дает гибкость: даже если наши бизнес-требования изменятся, у нас останутся исходные данные, которые можно будет трансформировать по-новому.
        
- **"Какое место в этой схеме занимают такие инструменты, как dbt, Fivetran, Airflow?"**
    
    - Ответ: Fivetran или Stitch — это инструменты для **EL** (Extract, Load). dbt — это инструмент для **T** (Transform). Airflow — это оркестратор, который управляет всем этим процессом, запуская задачи Fivetran, а затем dbt по расписанию.